# Final-report-team1

## 1. Metrics

#### FrontEnd

- Lines of Code 

  - Tool Used: `cloc`

  - Command: `cloc src/`

  - Result: 21502 lines of code

    | Language        | Files | Blank Lines | Comment Lines | Code Lines |
    | --------------- | ----- | ----------- | ------------- | ---------- |
    | SCSS            | 140   | 2312        | 1215          | 12136      |
    | Vuejs Component | 62    | 441         | 391           | 7563       |
    | JavaScript      | 30    | 99          | 82            | 1099       |
    | CSS             | 2     | 136         | 28            | 456        |
    | JSON            | 2     | 0           | 0             | 232        |
    | SVG             | 12    | 0           | 0             | 12         |
    | YAML            | 1     | 4           | 13            | 5          |
    | **Total**       | 249   | 2992        | 1729          | 21503      |

- Number of packages/modules 

  - Tool Used: Manual count via the `package.json` file
  - Result: 14 (dependencies) + 23 (devDependencies) = 37

- Number of source files

  - Tool Used: `find` command in the terminal
  - Command: `find src/ -type f -name "*.vue" -or -name "*.js" | wc -l`
  - Result: 93 source files

-  Number of dependencies

  - Tool Used: `npm list --depth=0`
  - Command: `npm list --depth=0`
  - Result: 36 dependencies

## 2. Documentation

Please refer to `readme.md` and `readme_for_developer.md`.

## 3. Tests

#### FrontEnd

We've encountered some challenges while using Jest for testing, which has prevented us from employing automated scripts. As a result, we've switched to manual testing for the time being. While this increases the time and effort required for testing, it provides us with a more intuitive testing process, allowing for a deeper understanding of the code's behavior and potential issues. Although manual testing may not be as efficient as automation, we remain committed to ensuring code quality and are actively working to address the current challenges so that we can resume automated testing as soon as possible. There are some figures that show our error.<img src="pics/test_error.png" style="zoom:40%;" />

Our manual testing primarily involves the following processes: console output and network packet capture.

1. **Console Output**: During manual testing, we carefully monitor the console output generated by our FrontEnd components. This involves checking for any error messages, warnings, or debug information that might indicate issues with the code. By examining the console output, we can identify potential bugs, unexpected behaviors, or performance issues that need to be addressed.
2. **Network Packet Capture**: Another crucial aspect of our manual testing process is capturing network packets to analyze the communication between the FrontEnd and backend systems. We use tools like Wireshark or browser developer tools to intercept and inspect the HTTP requests and responses exchanged during application operation. This allows us to verify that the FrontEnd correctly interacts with the backend services, as well as identify any anomalies, such as incorrect data transmission, slow response times, or unexpected server errors. By thoroughly examining network traffic, we ensure the integrity, security, and efficiency of our application's communication channels.

These manual testing procedures enable us to meticulously assess the behavior and performance of our FrontEnd components, ensuring they meet the desired specifications and deliver a seamless user experience.

## 4. Build

#### Tools

Node.js and npm: Used for managing project dependencies and running build scripts.

#### Tasks Executed in a Build

1. Dependency Installation: Use `npm install` to install all necessary dependencies for the project.
2. Compilation and Packaging: Use `npm run build` to compile the source code and produce the final deployable artifacts.

#### Build Process

- In the `vue.config.js` file, add `publicPath: './',` to `module.exports`
- Run `npm run build` in the `FrontEnd` folder.
- Find `dist` folder, open `index.html` in browser.

#### Final Artifacts

**dist folder**:

<img src="pics/build_dist.png" style="zoom:50%;" />

**index.html**:

<img src="pics/build_index.png" style="zoom:50%;" />

## 5. Deployment

In the `FrontEnd` folder:
- Create `Dockerfile` and `.dockerignore` files
  The `Dockerfile` is:
  ```
  FROM node:alpine
  WORKDIR /app
  COPY package.json .
  RUN npm install
  CMD ["npm", "run", "serve"]
  ```
  The `.dockerignore` file is:
  ```
  node_modules
  .git
  .gitignore
  dist
  ```
  
- Run `sudo docker build -t sustech_event:dev .` to create the docker image named `sustech_event`
  Note that if it raises an error `ERROR [internal] load metadata for docker.io/library/node:alpine`, please change the `credsStore` value in `$HOME/.docker/config.json` from `desktop` to `osxkeychain`.
  The result is:
  
  <img src="pics/dockerBuild.png" style="zoom:50%;" />
  
- Run `docker run -v ${PWD}:/app -v /app/node_modules -p 8089:8080 sustech_event:dev` to launch at port 8089

    The result is:

    <img src="pics/dockerRun.png" style="zoom:50%;" />

    <img src="pics/dockerSuccess.png" style="zoom:50%;" />

- Publish the image `sustech_event` to DockerHub